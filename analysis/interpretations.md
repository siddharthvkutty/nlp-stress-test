## Key Findings

1. Sentiment models exhibit high confidence on lexically polarized inputs but fail under pragmatic reversal.
2. Sarcasm induces the highest inter-model disagreement, indicating shallow semantic understanding.
3. Larger models do not eliminate failures; instead, they express uncertainty rather than confident misclassification.
4. Confidence collapse precedes outright prediction failure and can serve as an early warning signal.

## Implications

These results suggest that modern sentiment classifiers rely heavily on surface-level lexical cues and lack robust pragmatic reasoning, limiting their reliability in real-world review analysis.
